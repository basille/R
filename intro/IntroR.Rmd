% Introduction to R and exploration of the variance
% Mathieu Basille
% February 27, 2013


<!-- R & knitr options -->

```{r Rinit, include = FALSE, cache = FALSE}
options(keep.comment = FALSE, replace.assign = TRUE, width = 80)
opts_knit$set(stop_on_error = 2L)
opts_chunk$set(fig.path = 'figure/', fig.align = 'center', fig.show = 'hold', out.width = '.6\\textwidth', comment = NA)
library(knitcitations)
```

```{r knitr-inside-R, echo = FALSE, eval = FALSE}
library(knitr)
knit("IntroR.Rmd")
purl("IntroR.Rmd")
library(basr)
pandoc("IntroR.md")
```

> A new statistic proves that 73\% of all statistics are pure inventions. <cite>J.J.A. Weber</cite>

This document provides the basis to use the <img
src="https://www.r-project.org/Rlogo.jpg" alt="R" height="16"
width="21"> software. The first section is generic, and will
demonstrate the general use of the software, the different data
types[^fn1] and the available resources. The second section explore
the graphical capabilities of the software. Finally, the document
presents an exploration of the analysis of variance. For more details
about <img src="https://www.r-project.org/Rlogo.jpg" alt="R"
height="16" width="21">, see the
[Introduction to R](https://cran.r-project.org/doc/manuals/R-intro.pdf). The
<img src="https://www.r-project.org/Rlogo.jpg" alt="R" height="16"
width="21"> code used in this document can be found [here](IntroR.R).

[^fn1]: Data importation is not covered in this document.


## First use

### The R environment

<img src="https://www.r-project.org/Rlogo.jpg" alt="R" height="16"
width="21"> is a statistical environment based on a command-line
language.  <img src="https://www.r-project.org/Rlogo.jpg" alt="R"
height="16" width="21"> is a free software. You can thus *freely* use
it[^fn2], *freely* distribute it, and *freely* modify and redistribute
it.

[^fn2]: Available at: [https://www.r-project.org](https://www.r-project.org)

On Windows, if we launch the software, a window opens with a console,
in which we can type in commands. A few menus are available, although
they are rarely used. A look at `Help > Console` might help.

I strongly recommend, however, to use RStudio[^fn3], a free <img
src="https://www.r-project.org/Rlogo.jpg" alt="R" height="16"
width="21"> development environment. RStudio makes it easier to manage
code, objects, graphs, and also proposes advanced features, such as
the support of R Markdown.

[^fn3]: Available at: [https://www.rstudio.com/](https://www.rstudio.com/)


To start with, we check what is the working directory in which <img
src="https://www.r-project.org/Rlogo.jpg" alt="R" height="16"
width="21"> started:

```{r getwd, eval = FALSE}
getwd()
```

There are several methods to change this folder: among others, the
preferred approach should be the code-based approach:

```{r setwd, eval = FALSE}
setwd("C:/Documents and Settings/Me/My documents/My folder")
```

The command line accepts directly all kinds of arithmetic and standard
functions:

```{r calc}
2+2
pi
1:5
sqrt(26)
rnorm(10)
```



### Data types

In R, everything is an object: Data, functions, outputs, etc. are all
stored with the assignation command `<-`:

```{r assign}
foo <- 2+2
foo
```

`foo` is a numeric vector of length 1:

```{r class}
class(foo)
length(foo)
```

We can associate several numbers in the same vector with the function
`c` (for "combine"):

```{r combine}
foo <- c(42, 2+2, sqrt(26))
foo
class(foo)
length(foo)
```

Other common data types are matrices, data frames and lists:

```{r type}
mat <- matrix(1:20, nrow = 5)
mat
df <- data.frame(A = 1:5, B = seq(0, 1, length.out = 5))
df
class(df$B)
lis <- list(l1 = 1:10, l2 = seq(0, 1, length.out = 5))
lis
```

The most common structure for data is a data frame, i.e. a table with
observations as rows and variables as columns. A set of functions are
available to explore the data[^fn4]. Let's start with a simple data
frame with 20 observations over 4 variables of different types (A, B,
C and D):

[^fn4]: All these functions can be used on any data type, but will
only be demonstrated here on data frames. Feel free to explore with
other data types!

```{r df}
df <- data.frame(A = 1:20, B = seq(0, 1, length.out = 20), C = sample(c("Big", "Medium", "Small"), 20, replace = TRUE), D = rnorm(20))
head(df)
tail(df)
str(df)
summary(df)
names(df)
dim(df)
table(df$C)
```

We can also store a function in an object:

```{r func}
square <- function(x)
    print(paste("The square of", x, "is", x^2))
square(2)
```

All objects are stored in the user environment. It is possible to list the objects, to remove them, or to save the complete environment for further use[^fn5].

[^fn5]: The standard behavior is to do it interactively when the user
terminates a session.

```{r ls}
ls()
```
```{r save, eval = FALSE}
rm(mat)
save.image(file = "Session.RData")
```

### Need help? 

<img src="https://www.r-project.org/Rlogo.jpg" alt="R" height="16"
width="21"> provides a bunch of utilities to find answers: 

```{r help, eval = FALSE, tidy = FALSE}
help("sqrt")
?sqrt
help.start()
apropos("test")
help.search("Linear Model")
RSiteSearch("An Introduction to R")
```

`help` and `?` are equivalent functions to open the documentation of a
function, most often with working examples. `help.start()` opens the
documentation in HTML format directly in the browser. `apropos` looks
for every function that contains a given pattern in their
name. `help.search` search the request in the help files of the
installation. Finally, `RSiteSearch` sends the request to the browser
to search in on-line resources (mailing lists, help files, other
documents).

As of today, the best on-line resource to find answers related to a
<img src="https://www.r-project.org/Rlogo.jpg" alt="R" height="16"
width="21"> problem is [Rseek](http://rseek.org/), which is the
equivalent of `RSiteSearch` with a very detailed and user-friendly
output.


## Graphics

<img src="https://www.r-project.org/Rlogo.jpg" alt="R" height="16"
width="21"> has truly amazing capabilities when it comes to
graphics. In this section, I will review only simple ones, using base
functions. For more advanced users, I strongly recommend to have a
look at the `ggplot2` package[^fn6], which implements the grammar of
graphics in <img src="https://www.r-project.org/Rlogo.jpg" alt="R"
height="16" width="21">.

[^fn6]: See here: [http://ggplot2.org/](http://ggplot2.org/)


### Scatter plot

The most common graphical type is the 2D scatter plot, which
represents X and Y coordinates. Let's prepare 20 random x-coordinates
from a normal distribution (with mean equal to 0 and standard
deviation equal to 1). We model the y-coordinates based on the
following model:

$$x = 2 \times y + \epsilon$$

with $\epsilon$ being a noise also drawn from a normal distribution,
with mean equal to 0 and standard deviation equal to 0.5:

```{r model}
xx <- rnorm(20)
yy <- xx*2 + rnorm(20, 0, 0.5)
```

A scatterplot uses the generic function `plot`. We add a line with the
function `abline`, which uses an intercept (here 0) and a slope (here
2):

```{r plot, fig.cap = "Simple scatter plot."}
plot(xx, yy)
abline(a = 0, b = 2)
```

We can verify the match between the observed data (i.e. the generated
data) and the model using a simple linear regression (function `lm`):

```{r lm, fig.cap = "Simple scatter plot with linear model."}
plot(xx, yy)
abline(a = 0, b = 2)
lm1 <- lm(yy ~ xx)
abline(lm1, lty = 2, lwd = 2, col = "blue")
```


### Boxplots

Boxplots are made using the function `boxplot`:

```{r boxplot1, fig.cap = "Simple boxplot."}
boxplot(df$D)
```

```{r boxplot2, fig.cap = "Boxplot with the formula syntax."}
boxplot(df$D ~ df$C)
```


### Histograms

Let `rand` be a set of 1000 random samples drawn from a normal distribution with mean equal to 0 and standard deviation equal to 1. Here is how to create a histogram of this sample:

```{r hist1, fig.cap = "Simple histogram."}
rand <- rnorm(1000)
hist(rand)
```

```{r hist2, fig.cap = "Histogram with modified breaks."}
hist(rand, main = "Normal distribution (frequency)", br = -50:50/10)
```

```{r hist3, fig.cap = "Histogram with non-equal cells."}
hist(rand, main = "Normal distribution (frequency)", br = c(-5, -2, -1, -0.25, 0, 0.5, 1.5, 3, 5))
```

```{r hist4, fig.cap = "Density histogram."}
hist(rand, main = "Normal distribution (density)", br = -50:50/10, freq = FALSE)
lines(-50:50/10, dnorm(-50:50/10), lwd = 3, col = "red", lty = 2)
```


### Cross graphics

Let's use the generic `plot` function on a data frame. What does it show?

```{r plotdf, fig.cap = "Plot of a data frame."}
plot(df)
```

To understand it better, let's check the structure of the factor column:

```{r asnum}
unclass(df$C)
```


## Variance of iris

### Presentation

Let's have a look at one of the most famous data set from statistics:
the Fisher's (or Anderson's) iris data set. This data set is directly
available in <img src="https://www.r-project.org/Rlogo.jpg" alt="R"
height="16" width="21"> in the object `iris`. Let's check what kind of
object it is:

```{r iris}
class(iris)
head(iris)
str(iris)
```

This data set contains information measured on 50 flowers from 3
different iris species:

```{r iris2}
table(iris$Species)
```

Detailed information is available in the help page of the data set:

```{r irishelp, eval = FALSE, tidy = FALSE}
?iris
```

Let's check that the sepal length increases with the petal length,
whatever the species:

```{r sep, fig.cap = "Petal vs. sepal length."}
plot(iris$Sepal.Length, iris$Petal.Length)
abline(lm(iris$Petal.Length ~ iris$Sepal.Length))
```

Is this also true for each species separately?

```{r sep2, fig.cap = "Petal vs. sepal length, by species."}
plot(iris$Sepal.Length, iris$Petal.Length, col = as.numeric(iris$Species))
```

```{r sep3, fig.cap = "Petal vs. sepal length, using coplot."}
coplot(iris$Petal.Length ~ iris$Sepal.Length|iris$Species, columns = 3)
```


### Mean comparison

Let's now look at the petal widths. Let's check if they vary by species:

```{r width, fig.cap = "Petal width."}
boxplot(iris$Petal.Width ~ iris$Species)
```

We're interested in comparing the means:

```{r moy}
mean(iris$Petal.Width[iris$Species == "setosa"])
by(iris$Petal.Width, iris$Species, mean)
iris$Mean <- rep(by(iris$Petal.Width, iris$Species, mean), each = 50)
```

Based on their values only, these means seem clearly different. We can
test them 2 by 2 with *t* tests (the parameter `var.equal = TRUE`
indicates that the variances are equal within each group):

```{r t.test}
t.test(iris$Petal.Width[1:50], iris$Petal.Width[51:100], var.equal = TRUE)
t.test(iris$Petal.Width[51:100], iris$Petal.Width[101:150], var.equal = TRUE)
t.test(iris$Petal.Width[1:50], iris$Petal.Width[101:150], var.equal = TRUE)
```

Even though the difference are significant, we are limited by the
multiplication of tests (if we had 10 classes, we would have needed 45
tests!) which ends up in multiplicative risks of error.  This is why
we need to use an analysis of variance (ANOVA) that can deal with this
problem in one single test.


### Partitioning the variance

The total variance can be split in a treatment variance and an error
variance. Let's have a look at the total variance first:

```{r var}
(totvar <- 1/nrow(iris) * sum((iris$Petal.Width - mean(iris$Petal.Width))^2))
```

Let's compare this result with the output of the function `var`:

```{r var2}
var(iris$Petal.Width)
totvar*nrow(iris)/(nrow(iris)-1)
```

According to the documentation of `var`, "the denominator $n - 1$ is
     used which gives an unbiased estimator of the variance for
     i.i.d. observations." We can create a function to compute the variance with a $n$ denominator instead of $n - 1$:

```{r varN}
varN <- function(x) 1/length(x) * sum((x - mean(x))^2)
varN(iris$Petal.Width)
```

We can now proceed with the partitioning of the variance:

```{r partition}
(treatvar <- 1/nrow(iris) * sum((iris$Mean - mean(iris$Petal.Width))^2))
(errvar <- 1/nrow(iris) * sum((iris$Petal.Width - iris$Mean)^2))
```

Let's check that the total variance is equal to the sum of the other two:

```{r sum}
treatvar + errvar
```

There is a dedicated function for an analysis of variance: the function `aov`, which gives directly the different sums of squares: 

```{r aov}
aov(iris$Petal.Width ~ iris$Species)
```

We can compute the treatment and error variances based on the sums of squares:

```{r aov2}
80.41333/150
6.15660/150
```


### Tests and conclusions

The contribution of the treatment variance in the total variance is given by 
$\eta^2 = V_{Treatments} / V_{Total}$:
<!-- $\eta^2 = \frac{V_{Treatments}}{V_{Total}}$ -->

```{r eta}
treatvar/totvar
```

The actual ANOVA test can be performed with the `ANOVA` function, based on the linear model that we want to try:

```{r anova}
anova(lm(iris$Petal.Width ~ iris$Species))
```

*Conclusions?*


## R session information

```{r Rexit, echo = FALSE}
print(sessionInfo(), locale = FALSE)
```
